{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sessions = np.arange(25, 76)\n",
    "data = []\n",
    "\n",
    "# Load speeches\n",
    "for session in sessions:\n",
    "    directory = \"./TXT/Session \" + str(session) + \" - \" + str(1945 + session)\n",
    "    for filename in os.listdir(directory):\n",
    "        f = open(os.path.join(directory, filename))\n",
    "        if filename[0] == \".\": #ignore hidden files\n",
    "            continue\n",
    "        splt = filename.split(\"_\")\n",
    "        data.append([session, 1945 + session, splt[0], f.read()])\n",
    "\n",
    "\n",
    "df_speech = pd.DataFrame(data, columns=['Session','Year','ISO-alpha3 Code','Speech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load country codes\n",
    "df_codes = pd.read_csv(\"UNSD — Methodology.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_label</th>\n",
       "      <th>evidences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Global warming is driving polar bears toward e...</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>[{'evidence_id': 'Extinction risk from global ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>The sun has gone into ‘lockdown’ which could c...</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>[{'evidence_id': 'Famine:386', 'evidence_label...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>The polar bear population has been growing.</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>[{'evidence_id': 'Polar bear:1332', 'evidence_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Ironic' study finds more CO2 has slightly cool...</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>[{'evidence_id': 'Atmosphere of Mars:131', 'ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Human additions of CO2 are in the margin of er...</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>[{'evidence_id': 'Carbon dioxide in Earth's at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>3125</td>\n",
       "      <td>About 60% of the warming observed from 1970 to...</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>[{'evidence_id': 'Climate variability:103', 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>3127</td>\n",
       "      <td>\"Skeptics hope that Postma’s alternative therm...</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>[{'evidence_id': 'Meteorology:4', 'evidence_la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>3130</td>\n",
       "      <td>\"There are other possible causes for climate c...</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>[{'evidence_id': 'Attribution of recent climat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>3131</td>\n",
       "      <td>We don't need a high heat flow - just a high t...</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>[{'evidence_id': 'Earth:161', 'evidence_label'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>3134</td>\n",
       "      <td>Over the last decade, heatwaves are five times...</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>[{'evidence_id': 'Bushfires in Australia:126',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1535 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      claim_id                                              claim  \\\n",
       "0            0  Global warming is driving polar bears toward e...   \n",
       "1            5  The sun has gone into ‘lockdown’ which could c...   \n",
       "2            6        The polar bear population has been growing.   \n",
       "3            9  Ironic' study finds more CO2 has slightly cool...   \n",
       "4           10  Human additions of CO2 are in the margin of er...   \n",
       "...        ...                                                ...   \n",
       "1530      3125  About 60% of the warming observed from 1970 to...   \n",
       "1531      3127  \"Skeptics hope that Postma’s alternative therm...   \n",
       "1532      3130  \"There are other possible causes for climate c...   \n",
       "1533      3131  We don't need a high heat flow - just a high t...   \n",
       "1534      3134  Over the last decade, heatwaves are five times...   \n",
       "\n",
       "          claim_label                                          evidences  \n",
       "0            SUPPORTS  [{'evidence_id': 'Extinction risk from global ...  \n",
       "1            SUPPORTS  [{'evidence_id': 'Famine:386', 'evidence_label...  \n",
       "2             REFUTES  [{'evidence_id': 'Polar bear:1332', 'evidence_...  \n",
       "3             REFUTES  [{'evidence_id': 'Atmosphere of Mars:131', 'ev...  \n",
       "4             REFUTES  [{'evidence_id': 'Carbon dioxide in Earth's at...  \n",
       "...               ...                                                ...  \n",
       "1530  NOT_ENOUGH_INFO  [{'evidence_id': 'Climate variability:103', 'e...  \n",
       "1531  NOT_ENOUGH_INFO  [{'evidence_id': 'Meteorology:4', 'evidence_la...  \n",
       "1532         SUPPORTS  [{'evidence_id': 'Attribution of recent climat...  \n",
       "1533  NOT_ENOUGH_INFO  [{'evidence_id': 'Earth:161', 'evidence_label'...  \n",
       "1534         SUPPORTS  [{'evidence_id': 'Bushfires in Australia:126',...  \n",
       "\n",
       "[1535 rows x 4 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load climate related json file\n",
    "climate = pd.read_json('data/climate-fever-dataset-r1.jsonl', lines=True) # Source https://www.sustainablefinance.uzh.ch/en/research/climate-fever.html\n",
    "climate['claim'] = climate['claim'].map(str)\n",
    "climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 16)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_un_merged = df_speech.merge(df_codes)\n",
    "\n",
    "# Reorder\n",
    "df_un_merged[[\"Country or Area\", \"Region Name\", \"Sub-region Name\", \\\n",
    "    \"ISO-alpha3 Code\", \"Least Developed Countries (LDC)\", \"Session\", \"Year\", \"Speech\"]]\n",
    "\n",
    "# Reindex\n",
    "df_un_merged = df_un_merged.set_index([\"Year\", \"ISO-alpha3 Code\"])\n",
    "\n",
    "df_un_merged = df_un_merged[:1000] # Small version for now\n",
    "df_un_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocess(words):\n",
    "    sw = stopwords.words(\"english\")\n",
    "    clean = []\n",
    "    for w in words:\n",
    "        w = str.lower(w)\n",
    "        if (w not in sw) and (w.isalpha()):\n",
    "            clean.append(w)\n",
    "    return clean\n",
    "\n",
    "df_un_merged['Tokenized'] = df_un_merged['Speech'].apply(word_tokenize) # Takes long\n",
    "df_un_merged['Clean'] = df_un_merged['Tokenized'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Clean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/_libs/index.pyx:146\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:49\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Clean'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_un_merged\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexing.py:1074\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1071\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1073\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m-> 1074\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexing.py:1313\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1313\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexing.py:1261\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: \u001b[39mint\u001b[39m):\n\u001b[1;32m   1260\u001b[0m     \u001b[39m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1261\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/generic.py:4050\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4047\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[1;32m   4049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(index, MultiIndex):\n\u001b[0;32m-> 4050\u001b[0m     loc, new_index \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49m_get_loc_level(key, level\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m   4051\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m drop_level:\n\u001b[1;32m   4052\u001b[0m         \u001b[39mif\u001b[39;00m lib\u001b[39m.\u001b[39mis_integer(loc):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexes/multi.py:3159\u001b[0m, in \u001b[0;36mMultiIndex._get_loc_level\u001b[0;34m(self, key, level)\u001b[0m\n\u001b[1;32m   3157\u001b[0m         \u001b[39mreturn\u001b[39;00m indexer, maybe_mi_droplevels(indexer, ilevels)\n\u001b[1;32m   3158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3159\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_level_indexer(key, level\u001b[39m=\u001b[39;49mlevel)\n\u001b[1;32m   3160\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   3161\u001b[0m         \u001b[39misinstance\u001b[39m(key, \u001b[39mstr\u001b[39m)\n\u001b[1;32m   3162\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlevels[level]\u001b[39m.\u001b[39m_supports_partial_string_indexing\n\u001b[1;32m   3163\u001b[0m     ):\n\u001b[1;32m   3164\u001b[0m         \u001b[39m# check to see if we did an exact lookup vs sliced\u001b[39;00m\n\u001b[1;32m   3165\u001b[0m         check \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlevels[level]\u001b[39m.\u001b[39mget_loc(key)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexes/multi.py:3262\u001b[0m, in \u001b[0;36mMultiIndex._get_level_indexer\u001b[0;34m(self, key, level, indexer)\u001b[0m\n\u001b[1;32m   3258\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mslice\u001b[39m(i, j, step)\n\u001b[1;32m   3260\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3262\u001b[0m     idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_loc_single_level_index(level_index, key)\n\u001b[1;32m   3264\u001b[0m     \u001b[39mif\u001b[39;00m level \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lexsort_depth \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   3265\u001b[0m         \u001b[39m# Desired level is not sorted\u001b[39;00m\n\u001b[1;32m   3266\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mslice\u001b[39m):\n\u001b[1;32m   3267\u001b[0m             \u001b[39m# test_get_loc_partial_timestamp_multiindex\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexes/multi.py:2848\u001b[0m, in \u001b[0;36mMultiIndex._get_loc_single_level_index\u001b[0;34m(self, level_index, key)\u001b[0m\n\u001b[1;32m   2846\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   2847\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2848\u001b[0m     \u001b[39mreturn\u001b[39;00m level_index\u001b[39m.\u001b[39;49mget_loc(key)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Clean'"
     ]
    }
   ],
   "source": [
    "df_un_merged.loc['Clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
